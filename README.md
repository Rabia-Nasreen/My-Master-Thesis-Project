# Detection of anomaly and identifying contributing features in multivariate time series
Anomaly detection in multivariate time series data is a critical task in industrial monitoring and predictive maintenance. Recent advances in deep learning have improved the ability to detect anomaly, but accurately identifying contributing features remain challenging due to the complex and dynamic nature of such data. As per my research no solution is proposed till now to solve this task. In this work, I performed comparative study of different deep learning models. A comprehensive methodology involving preprocessing, prediction, threshold-based detection, and feature identification is proposed. The project is structured into two key components: (i) detecting anomalous time-steps based on prediction errors, and (ii) identifying the features responsible for those anomalies through an error matrix analysis. Various deep learning models, including FNN, LSTM, FFT-augmented LSTM model, CNN, FFT-augmented CNN model, RNN, Transformer, TCN, and an ensemble deep learning model is compared and evaluated. Evaluation metrics such as precision, recall, and F1-score are used to benchmark performance across multiple server datasets. The Transformer and LSTM-based models demonstrated superior performance in detecting anomalies, while for feature interpretation LSTM is performing better compared to all other models.
![image](https://github.com/user-attachments/assets/6341299d-aa9f-49c8-8f61-5982cc8b4ddd)
![image](https://github.com/user-attachments/assets/372ae249-d64c-4c55-83db-fb0b0e6c3c15)
The experimental results demonstrate the effectiveness of various deep learning models in both anomaly detection and feature identification tasks on multivariate time series data. In terms of anomalous time-step detection, the Transformer model achieved the best performance, with the highest F1 score of 0.7379, indicating a strong balance between precision (0.7802) and recall (0.7739). This was closely followed by the LSTM and TCN models, which also demonstrated strong capabilities in capturing temporal dependencies, achieving F1 scores of 0.7116 and 0.7139, respectively. The CNN + FFT model showed notably high recall (0.8215), making it highly sensitive to detecting anomalies, although it suffered from a lower precision (0.6327), indicating a greater tendency toward false positives. Simpler architectures like FNN and RNN lagged behind, with relatively lower F1 scores, highlighting their limited capacity for modeling complex temporal patterns in sequential data.

When it comes to feature identification, the LSTM model again stood out with the highest F1 score of 0.6517, proving its effectiveness not only in identifying when anomalies occur but also in explaining which features contribute to those anomalies. The Transformer and TCN models followed, achieving F1 scores of 0.6264 and 0.6030, respectively, further demonstrating their robustness in multivariate settings. While FFT-augmented models such as CNN + FFT and LSTM + FFT showed good recall, their precision was notably lower, suggesting that frequency-based features helped detect anomalies but compromised the accuracy of feature attribution. The CNN-LSTM-Attention model provided moderate results in both tasks, suggesting that the inclusion of attention mechanisms contributes positively to interpretability, though not as effectively as pure LSTM or Transformer-based models.

Overall, the LSTM model emerged as the most balanced and interpretable approach, excelling in both detection and attribution tasks. It successfully leverages temporal patterns to not only identify abnormal behaviors but also finding the responsible features, making it particularly suitable for real-world anomaly detection systems that require both accuracy and explainability.

![image](https://github.com/user-attachments/assets/f84fb352-e494-444c-98f6-cb0e996d95a3)

Since the LSTM model demonstrated the highest F1 score for feature identification when compared to all other models on the complete dataset, it was selected for further evaluation using alternative interpretability logics. In the 50\% match logic approach—where predicted features are considered correct if at least half of the actual contributing features are identified—the LSTM model maintained strong performance across all three machines. It achieved an average F1 score of 0.7337, with a notably high average recall of 0.8618, indicating its capacity to capture the majority of relevant features even when precision was lower.

To assess its performance under more relaxed conditions, the model was also evaluated using the 1-match logic refer, which considers a prediction valid if at least one contributing feature is correctly identified. Under this framework, LSTM exhibited its highest interpretability performance, attaining an average F1 score of 0.7686 and an impressive recall of 0.8856. Most notably, the recall for Machine 1 reached as high as 0.9223, highlighting the model’s consistent ability to identify meaningful features associated with anomalies. These results reinforce the LSTM model's suitability not only for detecting anomalies but also for delivering reliable and interpretable feature-level explanations.
